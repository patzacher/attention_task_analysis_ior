---
title: "IOR Control Experiment Data Analysis" 
author: "P. Zacher" 
date: "2023-11-01" 
output: html_document 
editor_options: 
  markdown: 
    wrap: 72
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Load packages
```{r, warning=FALSE, message=FALSE}
library(psych) # for stats
library(readr) # for importing data
library(Hmisc) # for plotting
library(Rmisc) # for standard error calc
library(readxl) # for reading excel files
library(tidyverse) # packages for data science
library(plyr)
library(ez) # for stats
library(statmod)
library(ggplot2) # plotting
```

### Import Data 
The data contains observations for each participant who completed the task and
for each trial. Variables of interest are the trial number (`trialNum`),
duration the participant had to orient, engage, and disengage attention
(`ISIadj`), the number of attention shifts required to attend to the target
digit (`targetIndex`), whether the participant answered correctly (`correct`),
and the number of staircase reversals completed for each trial type
(`nReversals`).
```{r}
behavioral_data <- read.csv(file = "visual_shifting_ior_control_data.csv")
```

## Data Cleaning
Filter trials not at threshold (nReversal != 0). 
```{r, results='asis'}
behavioral_data_clean <- behavioral_data %>% filter(nReversal != 0)
behavioral_data_clean$ISIms <- behavioral_data_clean$ISIadj*1000
behavioral_data_clean$targetIndex <- as.factor(behavioral_data_clean$targetIndex)
```

### Figures
```{r}
# Mean shifting speed for each participant and target index
behavioral_data_summ_p <- behavioral_data_clean %>%
  dplyr::group_by(p, targetIndex) %>%
  dplyr::summarize(meanISIms = mean(ISIms))

# Use `summarySEwithin` function from the Rmisc package to calculate within-
# subject standard error.
behavioral_data_summ_se <- summarySEwithin(behavioral_data_summ_p,
                                           measurevar = "meanISIms",
                                           withinvars = "targetIndex",
                                           idvar = "p")

# Bar plot with points for mean performance for each participant and error bars
# representing the standard error corrected for within-subjects effects.
ggplot(behavioral_data_summ_se,
       aes(x = targetIndex,
           y = meanISIms,
           fill = targetIndex)) +
  geom_col(width = 0.75, color = "black") + 
  geom_errorbar(aes(y = meanISIms, 
                    ymin = meanISIms - se,
                    ymax = meanISIms + se,
                    width = 0.05)) +
  geom_point(data = behavioral_data_summ_p, 
             aes(x = targetIndex,
                 y = meanISIms),
             color = "black", 
             fill = "white", 
             shape = 21, 
             size = 1, 
             alpha = 0.75) + 
  xlab("Number of Shifts") + 
  ylab("Shifting Speed") + 
  labs(caption = "Bar plots represent the mean performance per condition. Points represent participant means, error bars represent 
       the within-subject standard error (Morey, 2008), calculated with the Rmisc package (Hope, 2013).") +
  theme_light() +
  theme(legend.position = "none")

```
## IN DEVELOPMENT
### ANOVA
```{r}
# Convert participant and target index cols to factor
behavioral_data_clean <- behavioral_data_clean %>%
  mutate(p = as.factor(p), targetIndex = as.factor(targetIndex))

# Compute ANOVA with target index as the within-subjects factor
behavioral_data_clean_ANOVA <- ezANOVA(
  behavioral_data_clean,
  dv = .(ISIms),
  wid = .(p),
  within = .(targetIndex),
  return_aov = TRUE
)
print(behavioral_data_clean_ANOVA)
```

## Effect Size - Partial Eta^2
```{r}
ss.eta2p(f=13.68458, dfn=7, dfd=63)
```

### Planned Contrasts
Compute planned contrasts because we have specific (directional, e.g., one 
condition is higher or lower than another) hypotheses that we want to 
test. Post-hoc tests (e.g., Tukey's HSD) would be appropriate if we had no
specific hypotheses.

```{r}
# Contrast 1 - Target Index. We expect fewer shifts can be completed
# significantly faster than more shifts. This is equivalent to weights of -1,
# -1, 1, 1. Significant (p < 0.005)
ss.w_contrast(SpatialExoNoPrac, dv = "ISIadj", 
              withinshow = c("targetIndex"), 
              wcont = c(-1, -1, 1, 1))

# Contrast 2 - Target Index. We expect one shift can be completed significantly
# faster than two shifts. This is equivalent to weights of -1, 1, 0, 0. Not
# significant (p = 0.19).
ss.w_contrast(SpatialExoNoPrac, dv = "ISIadj", 
              withinshow = c("targetIndex"), 
              wcont = c(-1, 1, 0, 0))

# Contrast 3 - Target Index. We expect seven shifts can be completed
# significantly faster than eight shifts. This is equivalent to weights of 0, 0,
# -1, 1. Not significant (p = 0.79).
ss.w_contrast(SpatialExoNoPrac, dv = "ISIadj", 
              withinshow = c("targetIndex"), 
              wcont = c(0, 0, -1, 1))

# Contrast 4 - Interaction.
ss.w_contrast(SpatialExoNoPrac, dv = "ISIadj", 
              withinshow = c("targetIndex", "task"), 
              wcont = c(0, 0, -1, 1))
```

### Tukey's HSD
# To use TukeyHSD(), we have to compute our ANOVA using aov().
```{r}
spatialExoANOVA2 <- aov(ISIadj ~ task + targetIndex + task*targetIndex, data = SpatialExoNoPrac)

# Check the results to make sure that it looks consistent.
summary(spatialExoANOVA2)
# Compute Tukey's HSD on all terms in the ANOVA.
spatialExoTukey <- TukeyHSD(spatialExoANOVA2)

# We are interested in only the significant effects in the interaction. First,
# we'll turn the list into a data frame and then filter it to find the
# significant differences.
spatialExoTukeyInt <- as.data.frame(spatialExoTukey$`task:targetIndex`)
spatialExoTukeyIntSig <- filter(spatialExoTukeyInt, `p adj` < 0.05)

# If we want to check we can use this function.
ss.w_HSD(SpatialExoNoPrac, dv="ISIms", withinshow=c("targetIndex","task"), sig_level = 0.05, SSE=461609.8, DFE=63)
```
